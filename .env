# =========================
# OpenAI (standard)
# =========================
OPENAI_API_KEY=sk-...           # ← wklej swój klucz
OPENAI_BASE_URL=                # opcjonalnie: własny endpoint/gateway (np. https://api.openai.com/v1)
OPENAI_ORG_ID=                  # opcjonalnie
OPENAI_PROJECT=                 # opcjonalnie
OPENAI_MODEL=gpt-4o-mini        # domyślny model dla appki

# =========================
# Azure OpenAI (jeśli używasz)
# =========================
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=          # np. https://twoja-nazwa.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=        # np. gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# =========================
# Aplikacja / środowisko
# =========================
APP_ENV=dev                     # dev | staging | prod
APP_NAME=intelligent-predictor

# =========================
# Baza danych / cache
# =========================
DATABASE_URL=sqlite:///data/app.db
REDIS_URL=                      # np. redis://localhost:6379/0 (opcjonalnie)

# =========================
# Vector DB (opcjonalnie)
# =========================
VECTOR_BACKEND=chroma           # chroma | pinecone (opcjonalnie)
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=
PINECONE_INDEX=

# =========================
# MLflow (opcjonalnie)
# =========================
MLFLOW_TRACKING_URI=
MLFLOW_EXPERIMENT_NAME=IntelligentPredictor

# =========================
# Logging (nadpisuje config.yaml)
# =========================
LOG_LEVEL=INFO
LOG_CONSOLE_LEVEL=INFO
LOG_FILE_LEVEL=DEBUG
LOG_ROTATION=25 MB
LOG_RETENTION=30 days
LOG_JSON=true
