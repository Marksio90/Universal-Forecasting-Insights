import io
import time
import json
import streamlit as st
import pandas as pd

from src.ai_engine.insights_generator import generate_insights
from src.utils.validators import basic_quality_checks

st.title("ü§ñ AI Insights ‚Äî PRO")

# ---------------------------
# Dane z sesji
# ---------------------------
df = st.session_state.get("df") or st.session_state.get("df_raw")
if df is None or not isinstance(df, pd.DataFrame) or df.empty:
    st.warning("Brak danych. Przejd≈∫ do Upload.")
    st.stop()

goal = st.session_state.get("goal", "Nie podano celu biznesowego")

# ---------------------------
# Sidebar: Opcje
# ---------------------------
with st.sidebar:
    st.subheader("‚öôÔ∏è Ustawienia analizy AI")
    depth = st.radio(
        "Tryb analizy",
        ["Szybka (kr√≥tkie wnioski)", "Pog≈Çƒôbiona (pe≈Çny raport)"],
        index=1,
    )
    include_schema = st.checkbox("Uwzglƒôdnij strukturƒô kolumn", value=True)
    include_quality = st.checkbox("Uwzglƒôdnij metryki jako≈õci danych", value=True)
    show_json = st.checkbox("Poka≈º surowy JSON (debug)", value=False)

# ---------------------------
# Kontekst danych
# ---------------------------
stats = basic_quality_checks(df)
meta = {
    "rows": stats["rows"],
    "cols": stats["cols"],
    "missing_pct": round(stats["missing_pct"] * 100, 2),
    "dupes": stats["dupes"],
}
schema = [
    {"col": c, "dtype": str(df[c].dtype), "nunique": int(df[c].nunique(dropna=True))}
    for c in df.columns
]

# ---------------------------
# Prompt building
# ---------------------------
prompt_parts = [
    f"Cel analizy: {goal}",
    f"Wielko≈õƒá danych: {meta['rows']}√ó{meta['cols']}, braki {meta['missing_pct']}%, duplikaty {meta['dupes']}",
]
if include_schema:
    prompt_parts.append(
        "Struktura danych:\n" + "\n".join([f"- {s['col']} ({s['dtype']}, {s['nunique']} unikalnych)" for s in schema[:25]])
        + ("..." if len(schema) > 25 else "")
    )
if include_quality:
    prompt_parts.append(
        "Metryki jako≈õci:\n" + json.dumps(meta, indent=2, ensure_ascii=False)
    )
prompt_parts.append(
    "Wygeneruj syntetyczny raport w formacie JSON z kluczami: "
    "`summary`, `top_insights`, `recommendations`, `risks`."
)
if depth.startswith("Pog≈Çƒôbiona"):
    prompt_parts.append(
        "Dodaj wiƒôcej szczeg√≥≈Ç√≥w, przyk≈Çady, rekomendacje KPI i hipotezy."
    )

user_prompt = "\n\n".join(prompt_parts)

# ---------------------------
# Cache dla AI (by uniknƒÖƒá ponownych ≈ºƒÖda≈Ñ)
# ---------------------------
@st.cache_data(show_spinner=False)
def cached_ai_insights(df_hash: str, prompt: str) -> dict:
    """Wraper do generate_insights, zwraca JSON"""
    try:
        txt = generate_insights(df, prompt)
        # Pr√≥ba sparsowania JSONa (je≈õli AI zwr√≥ci tekst)
        try:
            data = json.loads(txt)
            if isinstance(data, dict):
                return data
        except Exception:
            # fallback: wrzucamy ca≈Ço≈õƒá w summary
            return {"summary": txt}
    except Exception as e:
        return {"summary": f"B≈ÇƒÖd generowania insight√≥w: {e}"}
    return {"summary": "Brak wynik√≥w"}

# ---------------------------
# Hash danych (dla cache)
# ---------------------------
df_hash = str(hash(tuple(df.columns))) + str(len(df))

# ---------------------------
# Uruchomienie AI
# ---------------------------
if st.button("üîÆ Wygeneruj insighty", type="primary"):
    with st.spinner("Generujƒô insighty z OpenAI..."):
        t0 = time.time()
        insights = cached_ai_insights(df_hash, user_prompt)
        dt = time.time() - t0

    st.success(f"‚úÖ Wygenerowano w {dt:.1f}s")

    # -----------------------
    # Prezentacja wynik√≥w
    # -----------------------
    if "summary" in insights:
        st.markdown(f"### üß≠ Executive Summary\n{insights['summary']}")
    if "top_insights" in insights:
        st.markdown("### üìå Top Insights")
        for i, item in enumerate(insights["top_insights"], 1):
            st.markdown(f"{i}. {item}")
    if "recommendations" in insights:
        st.markdown("### üí° Rekomendacje")
        for i, item in enumerate(insights["recommendations"], 1):
            st.markdown(f"- {item}")
    if "risks" in insights:
        st.markdown("### ‚ö†Ô∏è Ryzyka / Anomalie")
        for i, item in enumerate(insights["risks"], 1):
            st.markdown(f"- {item}")

    # Eksport
    export_txt = io.StringIO()
    json.dump(insights, export_txt, ensure_ascii=False, indent=2)
    st.download_button(
        "‚¨áÔ∏è Pobierz insighty (JSON)",
        data=export_txt.getvalue(),
        file_name="ai_insights.json",
        mime="application/json",
    )

    if show_json:
        st.json(insights)
else:
    st.caption("Kliknij przycisk, aby wygenerowaƒá insighty z OpenAI.")
