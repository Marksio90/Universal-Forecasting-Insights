"""
Modu≈Ç Predictions (AutoML) PRO - Zaawansowane trenowanie modeli ML.

Funkcjonalno≈õci:
- AutoML pipeline z automatycznym wyborem algorytmu
- Pe≈Çna ewaluacja (classification/regression)
- Wizualizacje (confusion matrix, ROC, parity plot)
- Feature importance + SHAP values
- Multi-format export (model, metrics, predictions)
- Historia treningu
- Progress tracking
"""

from __future__ import annotations

import io
import json
import time
import logging
import hashlib
from typing import Optional, Literal, Any
from dataclasses import dataclass, asdict
from datetime import datetime

import joblib
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_auc_score,
    roc_curve,
    mean_squared_error,
    mean_absolute_error,
    r2_score,
)

from src.ml_models.automl_pipeline import train_automl
from src.utils.helpers import infer_problem_type

# ========================================================================================
# KONFIGURACJA
# ========================================================================================

logger = logging.getLogger(__name__)

# Limity bezpiecze≈Ñstwa
MAX_TRAIN_ROWS = 1_000_000
MAX_FEATURES = 1000
MIN_SAMPLES = 10
MAX_SHAP_SAMPLES = 5000
DEFAULT_SHAP_SAMPLES = 2000

# Hinty dla target detection
TARGET_NAME_HINTS = (
    "target", "y", "label", "sales", "sprzeda", "zuzy", "consum",
    "amount", "profit", "revenue", "price", "cena", "warto≈õƒá", "value"
)

ProblemType = Literal["classification", "regression", "timeseries"]


# ========================================================================================
# DATACLASSES
# ========================================================================================

@dataclass
class TrainingConfig:
    """Konfiguracja treningu modelu."""
    target: str
    test_size: float
    random_state: int
    enable_shap: bool
    shap_max_samples: int


@dataclass
class ModelMetrics:
    """Metryki modelu."""
    problem_type: ProblemType
    train_samples: int
    test_samples: int
    n_features: int
    training_time: float
    metrics: dict
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def to_dict(self) -> dict:
        """Konwertuje do s≈Çownika."""
        return asdict(self)


@dataclass
class TrainingResult:
    """Wynik treningu."""
    model: Any
    metrics: ModelMetrics
    X_test: pd.DataFrame
    y_test: pd.Series
    y_pred: np.ndarray
    feature_names: list[str]


# ========================================================================================
# UTILITY FUNCTIONS
# ========================================================================================

def _validate_dataframe(df: Optional[pd.DataFrame]) -> pd.DataFrame:
    """
    Waliduje DataFrame z session state.
    
    Args:
        df: DataFrame do walidacji
        
    Returns:
        Zwalidowany DataFrame
        
    Raises:
        ValueError: Je≈õli DataFrame jest nieprawid≈Çowy
    """
    if df is None:
        raise ValueError("Brak danych w session state")
    
    if not isinstance(df, pd.DataFrame):
        raise ValueError(f"Oczekiwano DataFrame, otrzymano {type(df)}")
    
    if df.empty:
        raise ValueError("DataFrame jest pusty")
    
    return df


def _validate_training_data(
    df: pd.DataFrame,
    target: str
) -> tuple[pd.DataFrame, pd.Series]:
    """
    Waliduje dane treningowe.
    
    Args:
        df: DataFrame z danymi
        target: Nazwa kolumny celu
        
    Returns:
        Tuple (X, y) - features i target
        
    Raises:
        ValueError: Je≈õli dane sƒÖ nieprawid≈Çowe
    """
    # Sprawd≈∫ czy target istnieje
    if target not in df.columns:
        raise ValueError(f"Kolumna celu '{target}' nie istnieje w danych")
    
    # Sprawd≈∫ rozmiar
    if len(df) < MIN_SAMPLES:
        raise ValueError(
            f"Za ma≈Ço pr√≥bek do treningu ({len(df)}). "
            f"Minimum: {MIN_SAMPLES}"
        )
    
    if len(df) > MAX_TRAIN_ROWS:
        raise ValueError(
            f"Za du≈ºo pr√≥bek ({len(df):,}). "
            f"Maksimum: {MAX_TRAIN_ROWS:,}"
        )
    
    # Przygotuj X i y
    y = df[target]
    X = df.drop(columns=[target])
    
    # Walidacja X
    if X.shape[1] == 0:
        raise ValueError("Brak kolumn cech (features)")
    
    if X.shape[1] > MAX_FEATURES:
        raise ValueError(
            f"Za du≈ºo cech ({X.shape[1]}). "
            f"Maksimum: {MAX_FEATURES}"
        )
    
    # Walidacja y
    if y.isna().all():
        raise ValueError("Wszystkie warto≈õci celu sƒÖ NaN")
    
    if y.isna().any():
        logger.warning(f"Target ma {y.isna().sum()} warto≈õci NaN - zostanƒÖ usuniƒôte")
        # Usu≈Ñ NaN z y i odpowiednie wiersze z X
        mask = ~y.isna()
        X = X[mask]
        y = y[mask]
    
    return X, y


def _detect_target_candidates(df: pd.DataFrame) -> list[str]:
    """
    Znajduje potencjalne kolumny docelowe.
    
    Args:
        df: DataFrame do przeszukania
        
    Returns:
        Lista nazw kolumn - kandydat√≥w
    """
    candidates = []
    
    for col in df.columns:
        col_lower = col.lower()
        if any(hint in col_lower for hint in TARGET_NAME_HINTS):
            candidates.append(col)
    
    return list(dict.fromkeys(candidates))  # Usu≈Ñ duplikaty


def _safe_train_test_split(
    X: pd.DataFrame,
    y: pd.Series,
    test_size: float,
    random_state: int,
    problem_type: Optional[str] = None
) -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    Bezpieczny split z walidacjƒÖ stratyfikacji.
    
    Args:
        X: Features
        y: Target
        test_size: Rozmiar zbioru testowego
        random_state: Seed dla reproducibility
        problem_type: Typ problemu (dla stratyfikacji)
        
    Returns:
        Tuple (X_train, X_test, y_train, y_test)
    """
    # Stratyfikacja dla klasyfikacji
    stratify = None
    if problem_type == "classification":
        # Sprawd≈∫ czy stratyfikacja mo≈ºliwa
        try:
            class_counts = y.value_counts()
            min_class_count = class_counts.min()
            
            # Musi byƒá minimum 2 pr√≥bki w najmniejszej klasie
            if min_class_count >= 2:
                stratify = y
            else:
                logger.warning(
                    f"Stratyfikacja niemo≈ºliwa - najmniejsza klasa ma "
                    f"{min_class_count} pr√≥bek"
                )
        except Exception as e:
            logger.warning(f"B≈ÇƒÖd sprawdzania stratyfikacji: {e}")
    
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=test_size,
            random_state=random_state,
            stratify=stratify
        )
        return X_train, X_test, y_train, y_test
        
    except Exception as e:
        logger.error(f"B≈ÇƒÖd split: {e}", exc_info=True)
        
        # Retry bez stratyfikacji
        logger.info("Retry bez stratyfikacji...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=test_size,
            random_state=random_state,
            stratify=None
        )
        return X_train, X_test, y_train, y_test


def _compute_classification_metrics(
    y_test: np.ndarray,
    y_pred: np.ndarray,
    model: Any
) -> dict:
    """
    Oblicza metryki dla klasyfikacji.
    
    Args:
        y_test: Prawdziwe warto≈õci
        y_pred: Predykcje
        model: Wytrenowany model
        
    Returns:
        S≈Çownik z metrykami
    """
    metrics = {}
    
    # Classification report
    try:
        report = classification_report(
            y_test, y_pred,
            output_dict=True,
            zero_division=0
        )
        metrics["classification_report"] = report
        
        # Extract key metrics
        if "accuracy" in report:
            metrics["accuracy"] = report["accuracy"]
        
        if "weighted avg" in report:
            metrics["f1_weighted"] = report["weighted avg"]["f1-score"]
            metrics["precision_weighted"] = report["weighted avg"]["precision"]
            metrics["recall_weighted"] = report["weighted avg"]["recall"]
            
    except Exception as e:
        logger.error(f"B≈ÇƒÖd classification report: {e}")
        metrics["classification_report_error"] = str(e)
    
    # Confusion matrix
    try:
        unique_labels = sorted(np.unique(y_test))
        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)
        metrics["confusion_matrix"] = cm.tolist()
        metrics["labels"] = unique_labels.tolist()
    except Exception as e:
        logger.error(f"B≈ÇƒÖd confusion matrix: {e}")
    
    # ROC AUC (je≈õli binary)
    if hasattr(model, "predict_proba"):
        try:
            proba = model.predict_proba(y_test.index)  # Use indices if available
            
            if proba.shape[1] == 2:  # Binary classification
                auc = roc_auc_score(y_test, proba[:, 1])
                metrics["roc_auc"] = float(auc)
                
        except Exception as e:
            logger.warning(f"ROC AUC pominiƒôty: {e}")
    
    return metrics


def _compute_regression_metrics(
    y_test: np.ndarray,
    y_pred: np.ndarray
) -> dict:
    """
    Oblicza metryki dla regresji.
    
    Args:
        y_test: Prawdziwe warto≈õci
        y_pred: Predykcje
        
    Returns:
        S≈Çownik z metrykami
    """
    metrics = {}
    
    try:
        metrics["rmse"] = float(mean_squared_error(y_test, y_pred, squared=False))
        metrics["mae"] = float(mean_absolute_error(y_test, y_pred))
        metrics["r2"] = float(r2_score(y_test, y_pred))
        
        # MSE
        metrics["mse"] = float(mean_squared_error(y_test, y_pred, squared=True))
        
        # MAPE (je≈õli nie ma zer)
        if not np.any(y_test == 0):
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
            metrics["mape"] = float(mape)
            
    except Exception as e:
        logger.error(f"B≈ÇƒÖd metryk regresji: {e}", exc_info=True)
        metrics["error"] = str(e)
    
    return metrics


def _extract_feature_importance(
    model: Any,
    feature_names: list[str],
    top_k: int = 30
) -> Optional[pd.Series]:
    """
    Ekstrahuje feature importance z modelu.
    
    Args:
        model: Wytrenowany model
        feature_names: Nazwy cech
        top_k: Liczba top cech do zwr√≥cenia
        
    Returns:
        Series z importance lub None
    """
    try:
        if hasattr(model, "feature_importances_"):
            importance = pd.Series(
                model.feature_importances_,
                index=feature_names
            ).sort_values(ascending=False).head(top_k)
            
            return importance
            
    except Exception as e:
        logger.warning(f"Nie uda≈Ço siƒô wyekstrahowaƒá feature importance: {e}")
    
    return None


def _compute_shap_values(
    model: Any,
    X_test: pd.DataFrame,
    max_samples: int,
    random_state: int
) -> Optional[tuple]:
    """
    Oblicza SHAP values z bezpiecznymi limitami.
    
    Args:
        model: Wytrenowany model
        X_test: Dane testowe
        max_samples: Maksymalna liczba pr√≥bek
        random_state: Seed
        
    Returns:
        Tuple (explainer, shap_values, X_sample) lub None
    """
    try:
        import shap
        
        # Pr√≥bkowanie
        n_samples = min(len(X_test), max_samples)
        X_sample = X_test.sample(n=n_samples, random_state=random_state)
        
        logger.info(f"Obliczam SHAP dla {n_samples} pr√≥bek...")
        
        # Wyb√≥r explainera na podstawie typu modelu
        model_name = model.__class__.__name__.lower()
        
        if any(tree_type in model_name for tree_type in [
            "lgbm", "xgb", "randomforest", "gradientboosting",
            "extratrees", "catboost"
        ]):
            # Tree explainer - szybki
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_sample)
            
        else:
            # Kernel explainer - wolniejszy, u≈ºyj mniejszej pr√≥bki
            kernel_samples = min(n_samples, 500)
            X_kernel = X_sample.sample(n=kernel_samples, random_state=random_state)
            
            logger.warning(
                f"Model nieobs≈Çugiwany przez TreeExplainer. "
                f"U≈ºywam KernelExplainer z {kernel_samples} pr√≥bkami (mo≈ºe byƒá wolny)"
            )
            
            explainer = shap.KernelExplainer(model.predict, X_kernel)
            shap_values = explainer.shap_values(X_kernel)
            X_sample = X_kernel
        
        return explainer, shap_values, X_sample
        
    except ImportError:
        logger.error("SHAP library nie jest zainstalowana")
        return None
    except Exception as e:
        logger.error(f"B≈ÇƒÖd obliczania SHAP: {e}", exc_info=True)
        return None


def _add_to_training_history(result: TrainingResult, config: TrainingConfig) -> None:
    """
    Dodaje wynik treningu do historii.
    
    Args:
        result: Wynik treningu
        config: Konfiguracja treningu
    """
    if "training_history" not in st.session_state:
        st.session_state["training_history"] = []
    
    # Metadane historii
    history_entry = {
        "timestamp": result.metrics.timestamp,
        "target": config.target,
        "problem_type": result.metrics.problem_type,
        "train_samples": result.metrics.train_samples,
        "test_samples": result.metrics.test_samples,
        "metrics": result.metrics.metrics,
        "test_size": config.test_size,
        "training_time": result.metrics.training_time
    }
    
    # Dodaj na poczƒÖtek
    st.session_state["training_history"].insert(0, history_entry)
    
    # Ogranicz do 10
    st.session_state["training_history"] = st.session_state["training_history"][:10]


# ========================================================================================
# STREAMLIT UI
# ========================================================================================

st.title("üìà Predictions (AutoML) ‚Äî PRO")

# ========================================================================================
# WALIDACJA DANYCH
# ========================================================================================

try:
    df_raw = st.session_state.get("df")
    df_main = _validate_dataframe(df_raw)
except ValueError as e:
    st.warning(f"‚ö†Ô∏è {e}")
    st.info(
        "Przejd≈∫ do **üì§ Upload Data** i u≈ºyj "
        "**üßπ Szybkie czyszczenie + FE**"
    )
    st.stop()

# ========================================================================================
# SIDEBAR: KONFIGURACJA
# ========================================================================================

with st.sidebar:
    st.subheader("‚öôÔ∏è Ustawienia treningu")
    
    # Target selection
    target_candidates = _detect_target_candidates(df_main)
    
    all_columns = list(df_main.columns)
    
    # Domy≈õlny index
    if target_candidates:
        default_idx = all_columns.index(target_candidates[0])
    else:
        default_idx = 0
    
    target = st.selectbox(
        "Kolumna celu",
        options=all_columns,
        index=default_idx,
        help="Wybierz zmiennƒÖ, kt√≥rƒÖ model ma przewidywaƒá"
    )
    
    st.caption(
        f"üí° Wykryto {len(target_candidates)} kandydat√≥w na cel"
        if target_candidates else
        "üí° Nie wykryto oczywistych kandydat√≥w"
    )
    
    st.divider()
    
    # Parametry splitu
    test_size = st.slider(
        "Wielko≈õƒá testu",
        min_value=0.1,
        max_value=0.4,
        value=0.2,
        step=0.05,
        help="Procent danych do walidacji"
    )
    
    random_state = st.number_input(
        "Random state",
        min_value=0,
        value=42,
        step=1,
        help="Seed dla reproducibility"
    )
    
    st.divider()
    
    # SHAP
    enable_shap = st.checkbox(
        "üß† Oblicz SHAP",
        value=True,
        help="Wyja≈õnialno≈õƒá modelu (mo≈ºe zajƒÖƒá chwilƒô)"
    )
    
    if enable_shap:
        shap_max_n = st.number_input(
            "Maks. pr√≥bek SHAP",
            min_value=200,
            max_value=MAX_SHAP_SAMPLES,
            value=DEFAULT_SHAP_SAMPLES,
            step=100,
            help=f"Maksimum: {MAX_SHAP_SAMPLES:,}"
        )
    else:
        shap_max_n = DEFAULT_SHAP_SAMPLES
    
    st.divider()
    
    # Historia
    history_count = len(st.session_state.get("training_history", []))
    st.caption(f"üìö Historia: {history_count} trening√≥w")

# Konfiguracja
config = TrainingConfig(
    target=target,
    test_size=test_size,
    random_state=random_state,
    enable_shap=enable_shap,
    shap_max_samples=shap_max_n
)

# Zapisz target do session
st.session_state["target"] = target

# ========================================================================================
# WYKRYWANIE TYPU PROBLEMU
# ========================================================================================

st.subheader("üéØ Detekcja typu problemu")

try:
    problem_type_hint = infer_problem_type(df_main, target)
    
    if problem_type_hint:
        # Info o typie
        type_emoji = {
            "classification": "üè∑Ô∏è",
            "regression": "üìä",
            "timeseries": "üìà"
        }
        
        emoji = type_emoji.get(problem_type_hint, "‚ùì")
        
        st.info(
            f"{emoji} Wykryto typ: **{problem_type_hint.upper()}**\n\n"
            f"Target: `{target}` ‚Ä¢ "
            f"Unikalne: {df_main[target].nunique()} ‚Ä¢ "
            f"Typ: {df_main[target].dtype}"
        )
    else:
        st.warning("‚ö†Ô∏è Nie uda≈Ço siƒô okre≈õliƒá typu problemu automatycznie")
        
except Exception as e:
    st.error(f"‚ùå B≈ÇƒÖd wykrywania typu: {e}")
    logger.error(f"B≈ÇƒÖd detekcji typu: {e}", exc_info=True)

# ========================================================================================
# PRZYCISK TRENINGU
# ========================================================================================

st.divider()

train_col1, train_col2 = st.columns([3, 1])

with train_col1:
    train_button = st.button(
        "üöÄ Trenuj AutoML",
        type="primary",
        use_container_width=True,
        help="Rozpocznij trening modelu"
    )

with train_col2:
    if st.button("üóëÔ∏è Wyczy≈õƒá historiƒô", use_container_width=True):
        st.session_state["training_history"] = []
        st.success("‚úÖ Historia wyczyszczona")
        st.rerun()

# ========================================================================================
# G≈Å√ìWNY PIPELINE TRENINGU
# ========================================================================================

if train_button:
    start_time = time.time()
    
    # Progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # ============================================================================
        # ETAP 1: WALIDACJA DANYCH (0-20%)
        # ============================================================================
        
        status_text.text("üîç Walidacja danych...")
        progress_bar.progress(10)
        
        X, y = _validate_training_data(df_main, target)
        
        st.success(
            f"‚úÖ Dane zwalidowane: {len(X):,} pr√≥bek √ó {X.shape[1]} cech"
        )
        
        progress_bar.progress(20)
        
        # ============================================================================
        # ETAP 2: SPLIT DANYCH (20-30%)
        # ============================================================================
        
        status_text.text("‚úÇÔ∏è Podzia≈Ç train/test...")
        progress_bar.progress(25)
        
        X_train, X_test, y_train, y_test = _safe_train_test_split(
            X, y,
            config.test_size,
            config.random_state,
            problem_type_hint
        )
        
        st.info(
            f"üìä Split: Train={len(X_train):,} ‚Ä¢ Test={len(X_test):,} "
            f"({config.test_size*100:.0f}%)"
        )
        
        progress_bar.progress(30)
        
        # ============================================================================
        # ETAP 3: TRENING MODELU (30-70%)
        # ============================================================================
        
        status_text.text("ü§ñ Trening modelu AutoML...")
        progress_bar.progress(40)
        
        # Przygotuj DataFrame dla train_automl
        df_train = X_train.copy()
        df_train[target] = y_train.values
        
        model, automl_metrics, detected_ptype = train_automl(df_train, target)
        
        training_time = time.time() - start_time
        
        st.success(
            f"‚úÖ Model wytrenowany! "
            f"Typ: **{detected_ptype.upper()}** ‚Ä¢ "
            f"Czas: **{training_time:.2f}s**"
        )
        
        # Zapisz do session
        st.session_state["model"] = model
        st.session_state["problem_type"] = detected_ptype
        
        progress_bar.progress(70)
        
        # ============================================================================
        # ETAP 4: PREDYKCJE (70-80%)
        # ============================================================================
        
        status_text.text("üîÆ Generujƒô predykcje...")
        progress_bar.progress(75)
        
        y_pred = model.predict(X_test)
        
        progress_bar.progress(80)
        
        # ============================================================================
        # ETAP 5: METRYKI (80-90%)
        # ============================================================================
        
        status_text.text("üìä Obliczam metryki...")
        progress_bar.progress(85)
        
        # Oblicz metryki specyficzne dla typu
        if detected_ptype == "classification":
            eval_metrics = _compute_classification_metrics(y_test, y_pred, model)
        elif detected_ptype == "regression":
            eval_metrics = _compute_regression_metrics(y_test, y_pred)
        else:
            eval_metrics = {"warning": "Nieznany typ problemu"}
        
        # Po≈ÇƒÖcz z metrykami AutoML
        eval_metrics.update(automl_metrics)
        
        # Stw√≥rz obiekt metryk
        model_metrics = ModelMetrics(
            problem_type=detected_ptype,
            train_samples=len(X_train),
            test_samples=len(X_test),
            n_features=X.shape[1],
            training_time=training_time,
            metrics=eval_metrics
        )
        
        progress_bar.progress(90)
        
        # ============================================================================
        # ETAP 6: FINALIZACJA (90-100%)
        # ============================================================================
        
        status_text.text("üíæ Zapisujƒô wyniki...")
        
        # Wynik treningu
        result = TrainingResult(
            model=model,
            metrics=model_metrics,
            X_test=X_test,
            y_test=y_test,
            y_pred=y_pred,
            feature_names=list(X.columns)
        )
        
        # Dodaj do historii
        _add_to_training_history(result, config)
        
        progress_bar.progress(100)
        status_text.empty()
        progress_bar.empty()
        
        st.success(f"üéâ Trening zako≈Ñczony pomy≈õlnie w {training_time:.2f}s!")
        
        # ============================================================================
        # PREZENTACJA WYNIK√ìW
        # ============================================================================
        
        st.divider()
        
        # Tab layout
        tabs = st.tabs([
            "üìä Metryki",
            "üìà Wizualizacje",
            "üè∑Ô∏è Feature Importance",
            "üß† SHAP",
            "üíæ Export"
        ])
        
        # ========================================================================
        # TAB 1: METRYKI
        # ========================================================================
        
        with tabs[0]:
            st.subheader("üìã Kluczowe metryki")
            
            if detected_ptype == "classification":
                # Metryki classification
                if "accuracy" in eval_metrics:
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("Accuracy", f"{eval_metrics['accuracy']:.4f}")
                    
                    if "f1_weighted" in eval_metrics:
                        col2.metric("F1 (weighted)", f"{eval_metrics['f1_weighted']:.4f}")
                    if "precision_weighted" in eval_metrics:
                        col3.metric("Precision", f"{eval_metrics['precision_weighted']:.4f}")
                    if "recall_weighted" in eval_metrics:
                        col4.metric("Recall", f"{eval_metrics['recall_weighted']:.4f}")
                
                # ROC AUC je≈õli jest
                if "roc_auc" in eval_metrics:
                    st.metric("ROC AUC", f"{eval_metrics['roc_auc']:.4f}")
                
                # Pe≈Çny raport
                with st.expander("üìÑ Pe≈Çny raport klasyfikacji", expanded=False):
                    if "classification_report" in eval_metrics:
                        st.json(eval_metrics["classification_report"])
                
            elif detected_ptype == "regression":
                # Metryki regression
                col1, col2, col3, col4 = st.columns(4)
                
                if "rmse" in eval_metrics:
                    col1.metric("RMSE", f"{eval_metrics['rmse']:.4f}")
                if "mae" in eval_metrics:
                    col2.metric("MAE", f"{eval_metrics['mae']:.4f}")
                if "r2" in eval_metrics:
                    col3.metric("R¬≤", f"{eval_metrics['r2']:.4f}")
                if "mape" in eval_metrics:
                    col4.metric("MAPE", f"{eval_metrics['mape']:.2f}%")
            
            # AutoML metrics
            with st.expander("ü§ñ AutoML Metrics", expanded=False):
                st.json(automl_metrics)
        
        # ========================================================================
        # TAB 2: WIZUALIZACJE
        # ========================================================================
        
        with tabs[1]:
            st.subheader("üìà Wizualizacje predykcji")
            
            if detected_ptype == "classification":
                # Confusion Matrix
                if "confusion_matrix" in eval_metrics and "labels" in eval_metrics:
                    cm = np.array(eval_metrics["confusion_matrix"])
                    labels = eval_metrics["labels"]
                    
                    fig_cm = px.imshow(
                        cm,
                        x=labels,
                        y=labels,
                        text_auto=True,
                        aspect="auto",
                        title="Confusion Matrix (Test Set)",
                        labels=dict(x="Predicted", y="True")
                    )
                    st.plotly_chart(fig_cm, use_container_width=True)
                
                # ROC Curve (je≈õli binary)
                if "roc_auc" in eval_metrics and hasattr(model, "predict_proba"):
                    try:
                        proba = model.predict_proba(X_test)
                        if proba.shape[1] == 2:
                            fpr, tpr, _ = roc_curve(y_test, proba[:, 1])
                            
                            fig_roc = go.Figure()
                            fig_roc.add_trace(go.Scatter(
                                x=fpr, y=tpr,
                                mode="lines",
                                name=f"ROC (AUC={eval_metrics['roc_auc']:.4f})"
                            ))
                            fig_roc.add_trace(go.Scatter(
                                x=[0, 1], y=[0, 1],
                                mode="lines",
                                line=dict(dash="dash", color="gray"),
                                name="Random"
                            ))
                            fig_roc.update_layout(
                                title="ROC Curve",
                                xaxis_title="False Positive Rate",
                                yaxis_title="True Positive Rate"
                            )
                            st.plotly_chart(fig_roc, use_container_width=True)
                    except Exception as e:
                        st.info(f"ROC curve pominiƒôty: {e}")
            
            elif detected_ptype == "regression":
                # Parity Plot
                df_parity = pd.DataFrame({
                    "y_true": y_test.values,
                    "y_pred": y_pred
                })
                
                fig_parity = px.scatter(
                    df_parity,
                    x="y_true",
                    y="y_pred",
                    title="Parity Plot (True vs Predicted)",
                    trendline="ols",
                    opacity=0.6
                )
                fig_parity.add_trace(go.Scatter(
                    x=[y_test.min(), y_test.max()],
                    y=[y_test.min(), y_test.max()],
                    mode="lines",
                    line=dict(dash="dash", color="red"),
                    name="Perfect"
                ))
                st.plotly_chart(fig_parity, use_container_width=True)
                
                # Residuals
                residuals = y_test.values - y_pred
                fig_resid = px.histogram(
                    x=residuals,
                    nbins=40,
                    title="Rozk≈Çad reszt (Residuals)",
                    labels={"x": "Residual"}
                )
                st.plotly_chart(fig_resid, use_container_width=True)
                
                # Residuals vs Predicted
                fig_resid_scatter = px.scatter(
                    x=y_pred,
                    y=residuals,
                    title="Residuals vs Predicted",
                    labels={"x": "Predicted", "y": "Residual"},
                    opacity=0.6
                )
                fig_resid_scatter.add_hline(y=0, line_dash="dash", line_color="red")
                st.plotly_chart(fig_resid_scatter, use_container_width=True)
        
        # ========================================================================
        # TAB 3: FEATURE IMPORTANCE
        # ========================================================================
        
        with tabs[2]:
            st.subheader("üè∑Ô∏è Wa≈ºno≈õƒá cech")
            
            importance = _extract_feature_importance(model, result.feature_names)
            
            if importance is not None:
                # Bar chart
                st.bar_chart(importance)
                
                # Table
                with st.expander("üìã Tabela wa≈ºno≈õci", expanded=False):
                    importance_df = importance.to_frame(name="importance")
                    st.dataframe(importance_df, use_container_width=True)
            else:
                st.info(
                    "‚ÑπÔ∏è Model nie udostƒôpnia feature importance.\n\n"
                    "Niekt√≥re modele (np. linear) nie majƒÖ atrybutu "
                    "`feature_importances_`. Sprawd≈∫ SHAP dla wyja≈õnialno≈õci."
                )
        
        # ========================================================================
        # TAB 4: SHAP
        # ========================================================================
        
        with tabs[3]:
            st.subheader("üß† SHAP Analysis")
            
            if config.enable_shap:
                shap_button = st.button(
                    "üîÆ Oblicz SHAP values",
                    use_container_width=True,
                    help="Mo≈ºe zajƒÖƒá kilka minut dla du≈ºych danych"
                )
                
                if shap_button:
                    with st.spinner(f"Obliczam SHAP dla {config.shap_max_samples} pr√≥bek..."):
                        shap_result = _compute_shap_values(
                            model,
                            X_test,
                            config.shap_max_samples,
                            config.random_state
                        )
                    
                    if shap_result is not None:
                        explainer, shap_values, X_sample = shap_result
                        
                        st.success(f"‚úÖ SHAP obliczony dla {len(X_sample)} pr√≥bek")
                        
                        # Generuj wykres
                        try:
                            import matplotlib.pyplot as plt
                            
                            st.caption(
                                "üìä SHAP Summary Plot (beeswarm) - "
                                "pokazuje wp≈Çyw cech na predykcje"
                            )
                            
                            # Plot
                            fig, ax = plt.subplots(figsize=(10, 8))
                            
                            import shap
                            shap.summary_plot(
                                shap_values,
                                X_sample,
                                max_display=20,
                                show=False
                            )
                            
                            plt.tight_layout()
                            
                            # Wy≈õwietl w Streamlit
                            st.pyplot(fig, use_container_width=True)
                            plt.close()
                            
                        except Exception as e:
                            st.error(f"B≈ÇƒÖd generowania wykresu SHAP: {e}")
                            logger.error(f"SHAP plot error: {e}", exc_info=True)
                    else:
                        st.error("‚ùå Nie uda≈Ço siƒô obliczyƒá SHAP values")
                else:
                    st.info("üëÜ Kliknij przycisk aby obliczyƒá SHAP values")
            else:
                st.info(
                    "‚ÑπÔ∏è SHAP wy≈ÇƒÖczony w ustawieniach.\n\n"
                    "W≈ÇƒÖcz w sidebar, aby uzyskaƒá wyja≈õnialno≈õƒá modelu."
                )
        
        # ========================================================================
        # TAB 5: EXPORT
        # ========================================================================
        
        with tabs[4]:
            st.subheader("üíæ Eksport artefakt√≥w")
            
            col1, col2, col3 = st.columns(3)
            
            # Model export
            with col1:
                try:
                    model_bytes = io.BytesIO()
                    joblib.dump(model, model_bytes)
                    model_bytes.seek(0)
                    
                    st.download_button(
                        "‚¨áÔ∏è Model (.joblib)",
                        data=model_bytes,
                        file_name=f"model_{detected_ptype}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.joblib",
                        mime="application/octet-stream",
                        use_container_width=True
                    )
                except Exception as e:
                    st.error(f"B≈ÇƒÖd exportu modelu: {e}")
            
            # Metrics export
            with col2:
                try:
                    metrics_json = json.dumps(
                        model_metrics.to_dict(),
                        ensure_ascii=False,
                        indent=2
                    )
                    
                    st.download_button(
                        "‚¨áÔ∏è Metryki (.json)",
                        data=metrics_json,
                        file_name=f"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                        use_container_width=True
                    )
                except Exception as e:
                    st.error(f"B≈ÇƒÖd exportu metryk: {e}")
            
            # Predictions export
            with col3:
                try:
                    preds_df = pd.DataFrame({
                        "y_true": y_test.values,
                        "y_pred": y_pred if y_pred.ndim == 1 else np.argmax(y_pred, axis=1)
                    })
                    
                    preds_csv = preds_df.to_csv(index=False)
                    
                    st.download_button(
                        "‚¨áÔ∏è Predykcje (.csv)",
                        data=preds_csv,
                        file_name=f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                except Exception as e:
                    st.error(f"B≈ÇƒÖd exportu predykcji: {e}")
            
            st.divider()
            
            # Feature names export
            with st.expander("üìã Feature names (TXT)", expanded=False):
                features_txt = "\n".join(result.feature_names)
                st.download_button(
                    "‚¨áÔ∏è Pobierz listƒô cech",
                    data=features_txt,
                    file_name="features.txt",
                    mime="text/plain",
                    use_container_width=True
                )
        
    except ValueError as ve:
        progress_bar.empty()
        status_text.empty()
        
        st.error(f"‚ùå B≈ÇƒÖd walidacji: {ve}")
        
    except Exception as e:
        progress_bar.empty()
        status_text.empty()
        
        st.error(f"‚ùå B≈ÇƒÖd treningu: {e}")
        logger.error(f"Training error: {e}", exc_info=True)
        
        st.info(
            "üí° **Mo≈ºliwe rozwiƒÖzania:**\n"
            "- Sprawd≈∫ czy dane nie majƒÖ NaN w targecie\n"
            "- Zwiƒôksz liczbƒô pr√≥bek\n"
            "- Sprawd≈∫ czy target ma prawid≈Çowy typ\n"
            "- Spr√≥buj innego random_state"
        )

else:
    st.info(
        "üëÜ Ustaw parametry w sidebar i kliknij **Trenuj AutoML**\n\n"
        f"Target: **{target}** ‚Ä¢ "
        f"Test size: **{config.test_size*100:.0f}%** ‚Ä¢ "
        f"SHAP: **{'‚úì' if config.enable_shap else '‚úó'}**"
    )

# ========================================================================================
# HISTORIA TRENINGU
# ========================================================================================

history = st.session_state.get("training_history", [])

if history:
    st.divider()
    st.subheader("üìö Historia trening√≥w")
    
    for idx, hist_entry in enumerate(history):
        timestamp = hist_entry.get("timestamp", "Unknown")
        target_name = hist_entry.get("target", "N/A")
        ptype = hist_entry.get("problem_type", "N/A")
        train_time = hist_entry.get("training_time", 0)
        
        with st.expander(f"üïí {timestamp} | {target_name} ({ptype})", expanded=(idx == 0)):
            col1, col2, col3 = st.columns(3)
            col1.metric("Train samples", f"{hist_entry.get('train_samples', 0):,}")
            col2.metric("Test samples", f"{hist_entry.get('test_samples', 0):,}")
            col3.metric("Training time", f"{train_time:.2f}s")
            
            # Metryki
            metrics = hist_entry.get("metrics", {})
            if metrics:
                with st.expander("üìä Metryki", expanded=False):
                    st.json(metrics)

# ========================================================================================
# WSKAZ√ìWKI NAWIGACJI
# ========================================================================================

st.divider()
st.success(
    "‚ú® **Co dalej?**\n\n"
    "- **üìä EDA Analysis** ‚Äî przeanalizuj dane przed treningiem\n"
    "- **ü§ñ AI Insights** ‚Äî uzyskaj wnioski z AI\n"
    "- **üìà Forecasting** ‚Äî prognozy szereg√≥w czasowych\n"
    "- **üìÑ Reports** ‚Äî wygeneruj raport z treningu"
)